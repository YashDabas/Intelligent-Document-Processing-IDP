image: cloudwicklabs/bitbucketrunner:py312

definitions:
  scripts:
    - script: &auth_bootstrap_definition
        |
          chmod +x ./scripts/aws-auth-setup.sh
          ./scripts/aws-auth-setup.sh
    
    - script: &ssm_parameter_bootstrap_definition
        |
          chmod +x ./scripts/ssm-parameter-setup.sh
          ./scripts/ssm-parameter-setup.sh

  steps:
    - step: &pylint_full_code
        name: Pylint Full Lambda Code
        script:
          - |
            set -euo pipefail
            echo "Linting all the Lambda Codes & Common Modules"
            pip install --upgrade pylint
            #Linting Lambda Codes
            echo "Linting Lambda Codes"
            find api/lambdas/ -name "*.py" -print0 | xargs -0 -P 5 -n 1 pylint -j 0 --rcfile=config/pylintrc --fail-under=8
            echo "Lambda code linting is complete."
            #Linting Common Modules
            if [-d api/common-modules/ ]; then
              echo "Linting Common Modules"
              find api/common-modules/ -name "*.py" -print0 | xargs -0 -P 5 -n 1 pylint -j 0 --rcfile=config/pylintrc --fail-under=8
              echo "Lambda code linting is complete."
            else
              echo "api/common-modules directory found. Skipping."
            fi

    - step: &cfn_lint_entire_codebase
        name: CFN Linting
        oidc: true
        script:
          - *auth_bootstrap_definition
          - |
            set -euo pipefail
            pip install --upgrade cfn-lint awscli
            echo "Linting & Validating Cloudformation Templates"
            if ls infra/*.yaml > /dev/null 2>&1; then
              cfn-lint infra/*.yaml --ignore-checks W2001 W3005
            else
              echo "No Cloudformation Templates found. Skipping linting & validation"
            fi

    - step: &pre_requisite_resources_deployment
        name: Pre-Requisite Resources Creation
        oidc: true
        script:
          - *auth_bootstrap_definition
          - echo "Creating SSM Parameters."
          - *ssm_parameter_bootstrap_definition
          - |
            set -euo pipefail
            source config/default.conf
            pip install --upgrade awscli

            echo "Deploying Pre-Requisite Stack"
            aws cloudformation deploy \
              --region ${AWS_REGION} \
              --template-file "infra/PreRequisite.yaml" \
              --stack-name "${PROJECT_SHORT_NAME}-${ENVIRONMENT}-pre-requisite" \
              --capabilities CAPABILITY_NAMED_IAM CAPABILITY_IAM \
              --no-fail-on-empty-changeset \
              --parameter-overrides "pSSMProjectShortName=AIDP.CONFIG.PROJECT-SHORT-NAME" "pSSMEnvironment=AIDP.CONFIG.ENVIRONMENT" "pSSMCoreBucket=AIDP.CONFIG.CORE-BUCKET" "pSSMDriveSecret=AIDP.CONFIG.DRIVE-SECRET" "pDriveClientId=${DriveClientId}" "pDriveClientSecret=${DriveClientSecret}" "pDriveApiKey=${DriveApiKey}"

    - step: &stack_deployments
        name: CFT Deployment
        oidc: true
        script:
          - *auth_bootstrap_definition
          - |
            set -euo pipefail
            source config/default.conf
            pip install --upgrade awscli
            echo "Deploying Cloudformation Stacks"

            BUCKET_NAME=$(aws ssm get-parameter --name "AIDP.CONFIG.CORE-BUCKET" --query "Parameter.Value" --output text)

            echo "Deploying Infra Stack"
            aws cloudformation deploy \
              --region ${AWS_REGION} \
              --template-file "infra/Infra.yaml" \
              --stack-name "${PROJECT_SHORT_NAME}-${ENVIRONMENT}-infra" \
              --capabilities CAPABILITY_NAMED_IAM CAPABILITY_IAM \
              --s3-bucket ${BUCKET_NAME} \
              --s3-prefix cf-templates \
              --no-fail-on-empty-changeset \
              --parameter-overrides "pSSMProjectShortName=AIDP.CONFIG.PROJECT-SHORT-NAME" "pSSMEnvironment=AIDP.CONFIG.ENVIRONMENT" "pSSMVpcCidr=AIDP.CONFIG.VPC-CIDR" "pSSMPublicSubnetCidrs=AIDP.CONFIG.PUBLIC-SUBNET-CIDRS" "pSSMPrivateSubnetCidrs=AIDP.CONFIG.PRIVATE-SUBNET-CIDRS" "pSSMPrivateDBSubnetCidrs=AIDP.CONFIG.PRIVATE-DB-SUBNET-CIDRS" "pSSMAvailabilityZones=AIDP.CONFIG.AZS" "pSSMCoreBucket=AIDP.CONFIG.CORE-BUCKET" "pGoogleClientId=${GoogleClientId}" "pGoogleClientSecret=${GoogleClientSecret}"

            echo "Deploying Tables Stack"
            aws cloudformation deploy \
              --region ${AWS_REGION} \
              --template-file "infra/Tables.yaml" \
              --stack-name "${PROJECT_SHORT_NAME}-${ENVIRONMENT}-db" \
              --capabilities CAPABILITY_NAMED_IAM CAPABILITY_IAM \
              --s3-bucket ${BUCKET_NAME} \
              --s3-prefix cf-templates \
              --no-fail-on-empty-changeset \
              --parameter-overrides "pSSMProjectShortName=AIDP.CONFIG.PROJECT-SHORT-NAME" "pSSMEnvironment=AIDP.CONFIG.ENVIRONMENT" "pSSMCoreBucket=AIDP.CONFIG.CORE-BUCKET"

            echo "Deploying Lambda Stack"
            aws cloudformation deploy \
              --region ${AWS_REGION} \
              --template-file "infra/Lambda.yaml" \
              --stack-name "${PROJECT_SHORT_NAME}-${ENVIRONMENT}-lambda" \
              --capabilities CAPABILITY_NAMED_IAM CAPABILITY_IAM \
              --s3-bucket ${BUCKET_NAME} \
              --s3-prefix cf-templates \
              --no-fail-on-empty-changeset \
              --parameter-overrides "pSSMProjectShortName=AIDP.CONFIG.PROJECT-SHORT-NAME" "pSSMEnvironment=AIDP.CONFIG.ENVIRONMENT" "pSSMCoreBucket=AIDP.CONFIG.CORE-BUCKET" "pDriveClientId=${DriveClientId}" "pDriveClientSecret=${DriveClientSecret}" "pDriveApiKey=${DriveApiKey}" "pSSMEmailRecipient=AIDP.CONFIG.EMAIL"

            echo "Activating Email Rule Set"
            RULE_SET_NAME=$(aws cloudformation describe-stacks \
              --stack-name "${PROJECT_SHORT_NAME}-${ENVIRONMENT}-lambda" \
              --query "Stacks[0].Outputs[?OutputKey=='oReceiptRuleSet'].OutputValue" \
              --output text)
            echo "aws ses set-active-receipt-rule-set --rule-set-name $RULE_SET_NAME"
            aws ses set-active-receipt-rule-set --rule-set-name $RULE_SET_NAME
            echo "Email Rule Set activated"

            echo "Stacks deployed successfully."

    - step: &upload_lambda_layer_zips_to_s3
        name: Upload Lambda Layers Zip to S3
        oidc: true
        script:
          - *auth_bootstrap_definition
          - |
            set -euo pipefail
            echo "Uploading all Lambda Codes to S3 Bucket"
            BUCKET_NAME=$(aws ssm get-parameter --name "AIDP.CONFIG.CORE-BUCKET" --query "Parameter.Value" --output text)
            LAYER_SRC_DIR="api/lambda-layers"

            pip install --upgrade awscli

            if ls $LAYER_SRC_DIR/*.zip > /dev/null 2>&1; then
              for file in $LAYER_SRC_DIR/*.zip; do
                FILENAME=$(basename "$file")

                echo "Uploading $file to s3://${BUCKET_NAME}/lambda-layer/$FILENAME"
                aws s3 cp "$file" "s3://${BUCKET_NAME}/lambda-layer/$FILENAME" || {
                  echo "[ERROR] Failed to upload $FILENAME"
                  exit 1
                }
              done
              echo "All Lambda Layers have been successfully uploaded to S3"
            else
              echo "No zip files found for layers. Skipping upload"
            fi

    - step: &zip_and_upload_lambda_code_to_s3
        name: Zip & Upload to S3
        oidc: true
        script:
          - *auth_bootstrap_definition
          - |
            set -euo pipefail
            echo "Zipping and Uploading all Lambda Codes to S3 Bucket"
            BUCKET_NAME=$(aws ssm get-parameter --name "AIDP.CONFIG.CORE-BUCKET" --query "Parameter.Value" --output text)
            LAMBDA_SRC_DIR="api/lambdas"

            pip install --upgrade awscli

            if ls $LAMBDA_SRC_DIR/*.py > /dev/null 2>&1; then
              for file in $LAMBDA_SRC_DIR/*.py; do
                FILENAME=$(basename "$file")
                ZIP_FILE="${FILENAME}.zip"

                echo "Zipping $FILENAME into $ZIP_FILE"
                zip -j "$ZIP_FILE" "$file" > /dev/null

                echo "Uploading $ZIP_FILE to s3://${BUCKET_NAME}/lambda/$ZIP_FILE"
                aws s3 cp "$ZIP_FILE" "s3://${BUCKET_NAME}/lambda/$ZIP_FILE" || {
                  echo "[ERROR] Failed to upload $ZIP_FILE"
                  exit 1
                }
              done
              echo "All Lambda Codes have been zipped and successfully uploaded to S3"
            else
              echo "No Lambda Python files found. Skipping zip and upload"
            fi

    - step: &upload_step_function_definition_to_s3
        name: Upload the Step Function ASL to S3
        oidc: true
        script:
          - *auth_bootstrap_definition
          - |
            set -euo pipefail
            echo "Uploading the Step Function ASL to S3"
            BUCKET_NAME=$(aws ssm get-parameter --name "AIDP.CONFIG.CORE-BUCKET" --query "Parameter.Value" --output text)
            STEP_FUNCTION_SRC_DIR="step-functions"

            pip install --upgrade awscli
            
            if ls $STEP_FUNCTION_SRC_DIR/*.json > /dev/null 2>&1; then
              for file in $STEP_FUNCTION_SRC_DIR/*.json; do
                FILENAME=$(basename "$file")

                echo "Uploading $file to s3://${BUCKET_NAME}/step-functions/$FILENAME"
                aws s3 cp "$file" "s3://${BUCKET_NAME}/step-functions/$FILENAME" || {
                  echo "[ERROR] Failed to upload $FILENAME"
                  exit 1
                }
              done
              echo "All Step Function ASLs have been successfully uploaded to S3"
            else
              echo "No Step Function ASLs found. Skipping upload"
            fi
    
    - step: &upload_swagger_to_s3
        name: Upload the Api Swagger to S3
        oidc: true
        script:
          - *auth_bootstrap_definition
          - |
            set -euo pipefail
            echo "Uploading the API Swagger file to S3"
            BUCKET_NAME=$(aws ssm get-parameter --name "AIDP.CONFIG.CORE-BUCKET" --query "Parameter.Value" --output text)

            pip install --upgrade awscli

            echo "Uploading swagger.json to  s3://${BUCKET_NAME}/api/swagger.json"
            aws s3 cp "api/swagger.json" "s3://${BUCKET_NAME}/api/swagger.json" || {
              echo "[ERROR] Failed to upload api/swagger.json"
              exit 1
            }
            echo "Uploaded the Swagger to Core Bucket."

    - step: &ui_build_job
        name: Build the UI
        oidc: true
        script:
          - *auth_bootstrap_definition
          - |
            set -euo pipefail
            source config/default.conf

            pip install --upgrade awscli

            echo "Building UI from Web directory..."
            cd "web"

            REGION_VALUE=${AWS_REGION}

            echo "Fetching Cognito values from ${PROJECT_SHORT_NAME}-${ENVIRONMENT}-infra"
            USER_POOL_ID=$(aws cloudformation describe-stacks \
              --stack-name "${PROJECT_SHORT_NAME}-${ENVIRONMENT}-infra" \
              --region "${AWS_REGION}" \
              --query "Stacks[0].Outputs[?OutputKey=='oCognitoUserPoolId'].OutputValue" \
              --output text)

            CLIENT_ID=$(aws cloudformation describe-stacks \
              --stack-name "${PROJECT_SHORT_NAME}-${ENVIRONMENT}-infra" \
              --region "${AWS_REGION}" \
              --query "Stacks[0].Outputs[?OutputKey=='oCognitoClientId'].OutputValue" \
              --output text)
            
            COGNITO_DOMAIN=$(aws cloudformation describe-stacks \
              --stack-name "${PROJECT_SHORT_NAME}-${ENVIRONMENT}-infra" \
              --region "${AWS_REGION}" \
              --query "Stacks[0].Outputs[?OutputKey=='oCognitoDomain'].OutputValue" \
              --output text)

            echo "Fetching Rest API & WebSocket API URLs from ${PROJECT_SHORT_NAME}-${ENVIRONMENT}-lambda"
            API_URL=$(aws cloudformation describe-stacks \
              --stack-name "${PROJECT_SHORT_NAME}-${ENVIRONMENT}-lambda" \
              --region "${AWS_REGION}" \
              --query "Stacks[0].Outputs[?OutputKey=='oApiUrl'].OutputValue" \
              --output text)

            WEBSOCKET_API_URL=$(aws cloudformation describe-stacks \
              --stack-name "${PROJECT_SHORT_NAME}-${ENVIRONMENT}-lambda" \
              --region "${AWS_REGION}" \
              --query "Stacks[0].Outputs[?OutputKey=='oWebSocketUrl'].OutputValue" \
              --output text)

            echo "Creating .env file with Cognito values..."
            cat > .env <<EOF
            VITE_COGNITO_USER_POOL_ID="${USER_POOL_ID}"
            VITE_COGNITO_CLIENT_ID="${CLIENT_ID}"
            VITE_COGNITO_REGION="${REGION_VALUE}"
            VITE_COGNITO_DOMAIN="${COGNITO_DOMAIN}"
            VITE_API_URL="${API_URL}"
            VITE_WEBSOCKET_URL="${WEBSOCKET_API_URL}"
            EOF

            if ! command -v npm &> /dev/null; then
              yum install -y nodejs
            fi
            echo "Installing npm dependencies..."
            npm install --legacy-peer-deps || {
              echo "[ERROR] npm install failed"
              exit 1
            }
            echo "Checking if Vite is available..."
            if ! npx vite --version &> /dev/null; then
              echo "Installing Vite locally..."
              npm install --save-dev vite || {
                echo "[ERROR] Failed to install Vite"
                exit 1
              }
            fi

            echo "Running UI build..."
            npm run build || {
              echo "[ERROR] UI build failed"
              exit 1
            }
            echo "Build complete. Contents of dist/:"
            ls dist
        artifacts:
          - web/dist/**

    - step: &deploy_ui_to_s3
        name: Deploying UI build to S3
        oidc: true
        script:
          - *auth_bootstrap_definition
          - |
            set -euo pipefail
            source config/default.conf

            pip install --upgrade awscli

            echo "Deploying UI to S3..."
            UI_BUCKET_NAME="${PROJECT_SHORT_NAME}-${AWS_REGION}-${ACCOUNT_ID}-${ENVIRONMENT}-web-app-bucket"
            echo "Current working directory: $(pwd)"
            echo "Directory tree:"
            find .
            cd web
            if [ ! -d "dist" ]; then
              echo "[ERROR] dist/ folder not found"
              exit 1
            fi

            echo "Syncing contents to S3..."
            aws s3 sync dist/ "s3://${UI_BUCKET_NAME}/" --delete || {
              echo "[ERROR] S3 sync failed"
              exit 1
            }

            echo "Fetching CloudFront Distribution ID from stack outputs..."
            CLOUDFRONT_DISTRIBUTION_ID=$(aws cloudformation describe-stacks \
              --stack-name "${PROJECT_SHORT_NAME}-${ENVIRONMENT}-infra" \
              --region "${AWS_REGION}" \
              --query "Stacks[0].Outputs[?OutputKey=='oCloudFrontDistributionId'].OutputValue" \
              --output text)
            if [ -z "$CLOUDFRONT_DISTRIBUTION_ID" ]; then
              echo "[ERROR] Failed to fetch CloudFront Distribution ID from stack outputs"
              exit 1
            fi
            echo "Creating CloudFront invalidation..."
            aws cloudfront create-invalidation \
              --distribution-id "$CLOUDFRONT_DISTRIBUTION_ID" \
              --paths "/*" || {
                echo "[ERROR] CloudFront invalidation failed"
                exit 1
            }
            echo "UI successfully deployed and CloudFront cache invalidated."

pipelines:
  default:
    - step: *pylint_full_code
    - step: *cfn_lint_entire_codebase

  branches:
    develop:
      - step: *pylint_full_code
      - step: *cfn_lint_entire_codebase
      - step: *pre_requisite_resources_deployment
      - step: *upload_lambda_layer_zips_to_s3
      - step: *zip_and_upload_lambda_code_to_s3
      - step: *upload_step_function_definition_to_s3
      - step: *upload_swagger_to_s3
      - step: *stack_deployments
      - step: *ui_build_job
      - step: *deploy_ui_to_s3
    "feature-pranay":
      - step: *pylint_full_code
      - step: *cfn_lint_entire_codebase
      - step: *pre_requisite_resources_deployment
      - step: *upload_lambda_layer_zips_to_s3
      - step: *zip_and_upload_lambda_code_to_s3
      - step: *upload_step_function_definition_to_s3
      - step: *upload_swagger_to_s3
      - step: *stack_deployments
      - step: *ui_build_job
      - step: *deploy_ui_to_s3
    "feature-*":
      - step: *pylint_full_code
      - step: *cfn_lint_entire_codebase
